{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# English Moral Scoring: Aesop's Fables\n",
    "\n",
    "This notebook scores moral foundations in English children's literature (Aesop's Fables).\n",
    "\n",
    "## Process:\n",
    "1. Load English Master Moral Vectors (from validation notebook)\n",
    "2. Load cleaned Aesop's Fables\n",
    "3. Generate embeddings using IndicSBERT (same model for consistency)\n",
    "4. Calculate cosine similarity to moral foundations\n",
    "5. Visualize and compare with Tamil results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": "import os\nimport pickle\nfrom tqdm import tqdm\nimport numpy as np\nimport pandas as pd\nfrom sentence_transformers import SentenceTransformer\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Create output directory (in parent directory)\nos.makedirs('../phase3_outputs', exist_ok=True)\n\nsns.set_style(\"whitegrid\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## Step 1: Load English Master Moral Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": "# Load master vectors from validation notebook (in parent directory)\nwith open('../master_vectors_all_languages.pkl', 'rb') as f:\n    all_vectors = pickle.load(f)\n\n# Extract English vectors\nif 'english' in all_vectors:\n    master_vectors_english = all_vectors['english']\nelse:\n    raise FileNotFoundError(\"English master vectors not found in pickle file\")\n\n# Ensure numpy arrays\nfor k, v in master_vectors_english.items():\n    master_vectors_english[k] = np.array(v, dtype=np.float32)\n\nprint(f\"Loaded {len(master_vectors_english)} English master moral vectors:\")\nfor foundation in master_vectors_english.keys():\n    print(f\"  - {foundation}\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## Step 2: Load Cleaned Aesop's Fables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 284 fables\n",
      "\n",
      "Columns: ['fable_number', 'title', 'text', 'moral']\n",
      "\n",
      "First fable:\n",
      "fable_number                                                    1\n",
      "title                                      THE FOX AND THE GRAPES\n",
      "text            A hungry Fox saw some fine bunches of Grapes h...\n",
      "moral                                                         NaN\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Load the preprocessed fables\n",
    "df = pd.read_csv('processedDataEnglish/aesops_fables_cleaned.csv', encoding='utf-8')\n",
    "\n",
    "print(f\"Loaded {len(df)} fables\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "print(f\"\\nFirst fable:\")\n",
    "print(df.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## Step 3: Load Embedding Model\n",
    "\n",
    "Using the **same model** as Tamil (IndicSBERT) for cross-language consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: l3cube-pune/indic-sentence-similarity-sbert\n",
      "✓ Model loaded\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = 'l3cube-pune/indic-sentence-similarity-sbert'\n",
    "print(f\"Loading model: {MODEL_NAME}\")\n",
    "model = SentenceTransformer(MODEL_NAME)\n",
    "print(\"✓ Model loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## Step 4: Generate Embeddings for Fables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for 284 fables...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 9/9 [00:06<00:00,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Embeddings generated: (284, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract texts\n",
    "texts = df['text'].astype(str).tolist()\n",
    "\n",
    "print(f\"Generating embeddings for {len(texts)} fables...\")\n",
    "embeddings = model.encode(texts, show_progress_bar=True, convert_to_numpy=True)\n",
    "print(f\"✓ Embeddings generated: {embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## Step 5: Calculate Cosine Similarity to Moral Foundations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing similarity scores...\n",
      "✓ Similarity scores computed: (284, 10)\n",
      "\n",
      "First few scores:\n",
      "   care.virtue  care.vice  fairness.virtue  fairness.vice  loyalty.virtue  \\\n",
      "0     0.226500   0.253206         0.231159       0.298035        0.270405   \n",
      "1     0.251561   0.200681         0.227459       0.261651        0.266288   \n",
      "2     0.320856   0.387398         0.284212       0.340054        0.341983   \n",
      "3     0.377295   0.430981         0.358485       0.403133        0.390082   \n",
      "4     0.418126   0.336647         0.400727       0.354216        0.436591   \n",
      "\n",
      "   loyalty.vice  authority.virtue  authority.vice  sanctity.virtue  \\\n",
      "0      0.263454          0.245616        0.266740         0.269665   \n",
      "1      0.222719          0.245587        0.188370         0.261332   \n",
      "2      0.340156          0.347480        0.299541         0.363154   \n",
      "3      0.386400          0.455086        0.391337         0.415869   \n",
      "4      0.331591          0.410644        0.321784         0.408357   \n",
      "\n",
      "   sanctity.vice  \n",
      "0       0.345302  \n",
      "1       0.301305  \n",
      "2       0.391152  \n",
      "3       0.436239  \n",
      "4       0.378004  \n"
     ]
    }
   ],
   "source": [
    "def cosine_similarity_matrix(matA, vecsB):\n",
    "    \"\"\"\n",
    "    matA: (n, d) numpy array of embeddings\n",
    "    vecsB: dict of {label: (d,) }\n",
    "    returns: DataFrame of shape (n, len(vecsB)) with cosine similarities\n",
    "    \"\"\"\n",
    "    labels = list(vecsB.keys())\n",
    "    B = np.vstack([vecsB[l] for l in labels])  # (m, d)\n",
    "    \n",
    "    # Normalize\n",
    "    A_norm = matA / np.linalg.norm(matA, axis=1, keepdims=True)\n",
    "    B_norm = B / np.linalg.norm(B, axis=1, keepdims=True)\n",
    "    \n",
    "    # Compute similarity\n",
    "    sims = A_norm.dot(B_norm.T)  # (n, m)\n",
    "    df = pd.DataFrame(sims, columns=labels)\n",
    "    return df\n",
    "\n",
    "print(\"Computing similarity scores...\")\n",
    "scores_df = cosine_similarity_matrix(embeddings, master_vectors_english)\n",
    "print(f\"✓ Similarity scores computed: {scores_df.shape}\")\n",
    "print(f\"\\nFirst few scores:\")\n",
    "print(scores_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## Step 6: Identify Dominant Moral for Each Fable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell-13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results DataFrame: (284, 16)\n",
      "\n",
      "Dominant moral distribution:\n",
      "dominant_moral\n",
      "care.virtue         77\n",
      "loyalty.virtue      49\n",
      "sanctity.vice       41\n",
      "authority.virtue    35\n",
      "sanctity.virtue     35\n",
      "care.vice           23\n",
      "loyalty.vice        10\n",
      "authority.vice       7\n",
      "fairness.vice        5\n",
      "fairness.virtue      2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Combine with original dataframe\n",
    "result_df = pd.concat([df.reset_index(drop=True), scores_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Add dominant moral\n",
    "moral_cols = scores_df.columns.tolist()\n",
    "result_df['dominant_moral'] = scores_df.idxmax(axis=1)\n",
    "result_df['dominant_score'] = scores_df.max(axis=1)\n",
    "\n",
    "print(f\"Results DataFrame: {result_df.shape}\")\n",
    "print(f\"\\nDominant moral distribution:\")\n",
    "print(result_df['dominant_moral'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## Step 7: Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cell-15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "AESOP'S FABLES - MORAL FOUNDATION SCORES\n",
      "============================================================\n",
      "\n",
      "Average similarity scores:\n",
      "  authority.virtue    : 0.3076\n",
      "  sanctity.virtue     : 0.3066\n",
      "  care.virtue         : 0.3061\n",
      "  loyalty.virtue      : 0.2956\n",
      "  sanctity.vice       : 0.2913\n",
      "  care.vice           : 0.2787\n",
      "  fairness.virtue     : 0.2775\n",
      "  loyalty.vice        : 0.2764\n",
      "  fairness.vice       : 0.2622\n",
      "  authority.vice      : 0.2597\n",
      "\n",
      "Top 3 moral foundations:\n",
      "  1. authority.virtue    : avg=0.308, dominant in 35 fables\n",
      "  2. sanctity.virtue     : avg=0.307, dominant in 35 fables\n",
      "  3. care.virtue         : avg=0.306, dominant in 77 fables\n"
     ]
    }
   ],
   "source": [
    "# Average scores per moral foundation\n",
    "summary = result_df[moral_cols].mean().sort_values(ascending=False)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"AESOP'S FABLES - MORAL FOUNDATION SCORES\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nAverage similarity scores:\")\n",
    "for moral, score in summary.items():\n",
    "    print(f\"  {moral:20s}: {score:.4f}\")\n",
    "\n",
    "print(f\"\\nTop 3 moral foundations:\")\n",
    "for i, (moral, score) in enumerate(summary.head(3).items(), 1):\n",
    "    count = (result_df['dominant_moral'] == moral).sum()\n",
    "    print(f\"  {i}. {moral:20s}: avg={score:.3f}, dominant in {count} fables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## Step 8: Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "### 8.1: Bar Chart of Average Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": "fig, ax = plt.subplots(figsize=(12, 6))\n\nsummary.plot(kind='bar', ax=ax, color='steelblue', alpha=0.8)\nax.set_xlabel('Moral Foundation', fontsize=12)\nax.set_ylabel('Average Similarity Score', fontsize=12)\nax.set_title(\"Aesop's Fables: Average Moral Foundation Scores\", fontsize=14, fontweight='bold')\nax.tick_params(axis='x', rotation=45)\nax.grid(axis='y', alpha=0.3)\n\nplt.tight_layout()\nplt.savefig('../phase3_outputs/aesops_moral_scores_bar.png', dpi=300)\nplt.show()\n\nprint(\"✓ Saved bar chart to ../phase3_outputs/aesops_moral_scores_bar.png\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "### 8.2: Dominant Moral Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": "fig, ax = plt.subplots(figsize=(12, 6))\n\ndominant_counts = result_df['dominant_moral'].value_counts()\ndominant_counts.plot(kind='bar', ax=ax, color='coral', alpha=0.8)\nax.set_xlabel('Moral Foundation', fontsize=12)\nax.set_ylabel('Number of Fables', fontsize=12)\nax.set_title(\"Aesop's Fables: Dominant Moral Distribution\", fontsize=14, fontweight='bold')\nax.tick_params(axis='x', rotation=45)\nax.grid(axis='y', alpha=0.3)\n\nplt.tight_layout()\nplt.savefig('../phase3_outputs/aesops_dominant_moral_dist.png', dpi=300)\nplt.show()\n\nprint(\"✓ Saved distribution chart to ../phase3_outputs/aesops_dominant_moral_dist.png\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "### 8.3: UMAP Visualization (Optional - requires umap-learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": "try:\n    import umap\n    \n    print(\"Generating UMAP visualization...\")\n    reducer = umap.UMAP(n_components=2, random_state=42)\n    emb2d = reducer.fit_transform(embeddings)\n    \n    plt.figure(figsize=(12, 8))\n    \n    # Color by dominant moral\n    labels = result_df['dominant_moral'].astype(str)\n    unique_labels = labels.unique()\n    label2int = {l:i for i,l in enumerate(sorted(unique_labels))}\n    colors = [label2int[l] for l in labels]\n    \n    plt.scatter(emb2d[:,0], emb2d[:,1], c=colors, s=20, cmap='tab20', alpha=0.7)\n    plt.title(\"UMAP 2D: Aesop's Fables by Moral Foundation\", fontsize=14, fontweight='bold')\n    \n    # Legend (top 10 to avoid crowd)\n    import matplotlib.patches as mpatches\n    handles = []\n    for l in sorted(unique_labels)[:10]:\n        handles.append(mpatches.Patch(color=plt.cm.tab20(label2int[l]%20), label=l))\n    plt.legend(handles=handles, bbox_to_anchor=(1.05,1), loc=\"upper left\")\n    \n    plt.tight_layout()\n    plt.savefig('../phase3_outputs/aesops_umap.png', dpi=300, bbox_inches='tight')\n    plt.show()\n    \n    print(\"✓ Saved UMAP to ../phase3_outputs/aesops_umap.png\")\n    \nexcept ImportError:\n    print(\"⚠ UMAP not installed. Skipping UMAP visualization.\")\n    print(\"  To enable: pip install umap-learn\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "## Step 9: Compare with Tamil Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": "# Load Tamil results for comparison (from parent directory)\ntry:\n    thiru_summary = pd.read_csv('../phase3_outputs/thirukkural_moral_summary.csv', index_col=0)\n    aathi_summary = pd.read_csv('../phase3_outputs/aathichudi_moral_summary.csv', index_col=0)\n    \n    # Combine for comparison\n    comparison_df = pd.DataFrame({\n        'English_Aesop': summary,\n        'Tamil_Thirukkural': thiru_summary['0'],\n        'Tamil_Aathichudi': aathi_summary['0']\n    })\n    \n    print(\"\\n\" + \"=\"*60)\n    print(\"CROSS-LANGUAGE COMPARISON\")\n    print(\"=\"*60)\n    print(comparison_df.round(3))\n    \n    # Visualize comparison\n    fig, ax = plt.subplots(figsize=(14, 6))\n    \n    x = np.arange(len(comparison_df))\n    width = 0.25\n    \n    bars1 = ax.bar(x - width, comparison_df['English_Aesop'], width, \n                   label='English (Aesop)', alpha=0.8, color='steelblue')\n    bars2 = ax.bar(x, comparison_df['Tamil_Thirukkural'], width, \n                   label='Tamil (Thirukkural)', alpha=0.8, color='coral')\n    bars3 = ax.bar(x + width, comparison_df['Tamil_Aathichudi'], width, \n                   label='Tamil (Aathichudi)', alpha=0.8, color='lightgreen')\n    \n    ax.set_xlabel('Moral Foundation', fontsize=12)\n    ax.set_ylabel('Average Similarity Score', fontsize=12)\n    ax.set_title('Cross-Language Moral Foundation Comparison', fontsize=14, fontweight='bold')\n    ax.set_xticks(x)\n    ax.set_xticklabels(comparison_df.index, rotation=45, ha='right')\n    ax.legend()\n    ax.grid(axis='y', alpha=0.3)\n    \n    plt.tight_layout()\n    plt.savefig('../phase3_outputs/cross_language_comparison.png', dpi=300)\n    plt.show()\n    \n    print(\"\\n✓ Saved comparison chart to ../phase3_outputs/cross_language_comparison.png\")\n    \nexcept FileNotFoundError:\n    print(\"⚠ Tamil results not found. Run Step3.ipynb first to generate Tamil scores.\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-25",
   "metadata": {},
   "source": [
    "## Step 10: Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-26",
   "metadata": {},
   "outputs": [],
   "source": "# Save detailed scores (to parent directory)\nresult_df.to_csv('../phase3_outputs/aesops_moral_scores.csv', index=False, encoding='utf-8')\nprint(\"✓ Saved detailed scores to ../phase3_outputs/aesops_moral_scores.csv\")\n\n# Save summary\nsummary.to_csv('../phase3_outputs/aesops_moral_summary.csv')\nprint(\"✓ Saved summary to ../phase3_outputs/aesops_moral_summary.csv\")\n\n# Save embeddings\nnp.save('../phase3_outputs/aesops_embeddings.npy', embeddings)\nprint(\"✓ Saved embeddings to ../phase3_outputs/aesops_embeddings.npy\")\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"ALL DONE! English moral scoring complete.\")\nprint(\"=\"*60)"
  },
  {
   "cell_type": "markdown",
   "id": "cell-27",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### What We Did:\n",
    "1. ✅ Loaded English master moral vectors\n",
    "2. ✅ Loaded preprocessed Aesop's Fables\n",
    "3. ✅ Generated embeddings using IndicSBERT\n",
    "4. ✅ Calculated moral foundation scores\n",
    "5. ✅ Identified dominant morals\n",
    "6. ✅ Created visualizations\n",
    "7. ✅ Compared with Tamil results\n",
    "\n",
    "### Next Steps:\n",
    "- Run cross-cultural statistical analysis (Spearman, JSD)\n",
    "- Compare English vs Tamil moral distributions\n",
    "- Analyze cultural differences in moral values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6y5q7kw9jqn",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "from scipy.stats import entropy\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}