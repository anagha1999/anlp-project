{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/anagha1999/anlp-project/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ikjyd24qz9v",
        "outputId": "234d5b1e-9a39-4332-de7f-2a61c40bf424"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'anlp-project' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55835c53",
        "outputId": "0b4bfc77-0403-4aac-8ca9-6f841bf53d05"
      },
      "source": [
        "import requests\n",
        "import os\n",
        "\n",
        "urls = [\n",
        "    \"https://raw.githubusercontent.com/crvineeth97/kannada-stop-words/refs/heads/master/stop-words.txt\"\n",
        "]\n",
        "\n",
        "for url in urls:\n",
        "    filename = url.split('/')[-1]\n",
        "    response = requests.get(url)\n",
        "    with open(filename, 'wb') as f:\n",
        "        f.write(response.content)\n",
        "    print(f\"Downloaded: {filename}\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded: stop-words.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f22373c3"
      },
      "source": [
        "**Reasoning**:\n",
        "Install the `pypdf` library to enable PDF text extraction.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55110b35",
        "outputId": "87d8dd61-08ce-4965-c674-5c655cc8b3a3"
      },
      "source": [
        "!pip install pypdf"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.12/dist-packages (6.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "566cdbd6",
        "outputId": "b84da9f4-f901-400b-b54c-4b26e37a5c7d"
      },
      "source": [
        "import os\n",
        "import requests\n",
        "from pypdf import PdfReader\n",
        "\n",
        "# Define filenames and page ranges\n",
        "pdf_configs = [\n",
        "    {'filename': '1-janapada-kathegalu.pdf', 'start': 17, 'end': 236},\n",
        "    {'filename': \"Satrii_Niiti_Kathegal'u_text.pdf\", 'start': 10, 'end': 225}\n",
        "]\n",
        "\n",
        "# Directory where the repo was cloned\n",
        "repo_dir = 'anlp-project/kannada/kannada-dataset'\n",
        "\n",
        "extracted_texts = {}\n",
        "\n",
        "for config in pdf_configs:\n",
        "    filename = config['filename']\n",
        "    start_page = config['start']\n",
        "    end_page = config['end']\n",
        "\n",
        "    # 1. Try to find the file in the repo directory\n",
        "    file_path = os.path.join(repo_dir, filename)\n",
        "\n",
        "    # 2. If not found, check current directory\n",
        "    if not os.path.exists(file_path):\n",
        "        file_path = filename\n",
        "\n",
        "    # 3. If still invalid or corrupt, download it\n",
        "    if not os.path.exists(file_path) or os.path.getsize(file_path) < 1000:\n",
        "        print(f\"File {filename} missing or corrupt. Downloading...\")\n",
        "        url = f\"https://github.com/anagha1999/anlp-project/raw/main/kannada-dataset/{filename}\"\n",
        "        response = requests.get(url)\n",
        "        if response.status_code == 200:\n",
        "            with open(filename, 'wb') as f:\n",
        "                f.write(response.content)\n",
        "            file_path = filename\n",
        "        else:\n",
        "             print(f\"Failed to download {filename}\")\n",
        "\n",
        "    print(f\"Processing file: {file_path}\")\n",
        "\n",
        "    try:\n",
        "        reader = PdfReader(file_path)\n",
        "        text_content = []\n",
        "        # Convert 1-based page numbers to 0-based indices\n",
        "        # range(start, end) in python excludes end, so we need end_page (since we want up to end_page)\n",
        "        # Instructions say: 1-janapada-kathegalu.pdf: pages 17 to 236.\n",
        "        # Python index for page 17 is 16.\n",
        "        # We want to include page 236. So range should go up to 236 (index 235).\n",
        "        # range(16, 236) covers indices 16 to 235.\n",
        "        for i in range(start_page - 1, end_page):\n",
        "            if i < len(reader.pages):\n",
        "                page = reader.pages[i]\n",
        "                text_content.append(page.extract_text())\n",
        "\n",
        "        extracted_texts[filename] = \"\\n\".join(text_content)\n",
        "        print(f\"Successfully extracted text from {filename}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting text from {file_path}: {e}\")\n",
        "\n",
        "# Print the first 500 characters of each extracted text\n",
        "for filename, text in extracted_texts.items():\n",
        "    print(f\"\\n--- Start of {filename} ---\")\n",
        "    print(text[:500])\n",
        "    print(f\"--- End of Preview ---\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file: anlp-project/kannada/kannada-dataset/1-janapada-kathegalu.pdf\n",
            "Successfully extracted text from 1-janapada-kathegalu.pdf\n",
            "File Satrii_Niiti_Kathegal'u_text.pdf missing or corrupt. Downloading...\n",
            "Failed to download Satrii_Niiti_Kathegal'u_text.pdf\n",
            "Processing file: Satrii_Niiti_Kathegal'u_text.pdf\n",
            "Error extracting text from Satrii_Niiti_Kathegal'u_text.pdf: [Errno 2] No such file or directory: \"Satrii_Niiti_Kathegal'u_text.pdf\"\n",
            "\n",
            "--- Start of 1-janapada-kathegalu.pdf ---\n",
            "೧. ಮುತುಗದ ಎಲೆ ಗೋತಾಯಿ \n",
            "ಒಂದ್‌ ಪಟ್ಟಣ. ಒಬ್ಬ ದೊಡ್ಡ ದೊರೆ. ಆ ದೊಡ್ಡ ದೊರೆಗೆ ಏಳ್‌ ಜನ ಮಕ್ಕಳು. ಆ \n",
            "ಏಳ್‌ ಜನ ಮಕ್ಕಳಿಗೂ ಚೆನ್ನಾಗಿ ಓದ್ದಿ, ಓದ್‌ ಬಂದೋರ್‌ಗೆ ಹಾಲು ತುಪ್ಪ ಅನ್ನ ಹಾಕಿ \n",
            "ಮಂಚದ ಮೇಲೆ ಕೂಡ್ರಿಸಿ ಚೆನ್ನಾಗಿ ಸಾಕೋರು. ಏಳು ಜನ ಮಕ್ಕಳೂವೆ ಹೆಣ್‌ ಮಕ್ಕಳೇ \n",
            "ಹುಟ್ಟಿದ್ದಾರಲ್ಲ ಅಂತ, ಆ ದೊರೆ ಒಂದಿನ ಹೆಣ್‌ಮಕ್ಕಳನ್ನೆಲ್ಲ ಕೇಳಿದನು, ನನ್ನಾರವ್ವ \n",
            "ಸಾಕೋರು ಅಂತ. ಆರು ಜನ ಮಕ್ಕಳೂವೆ ನಾನ್‌ ಸಾಕ್ತೀನಿ, ನಾನ್‌ ಸಾಕ್ತೀನಿಅಂತ ಅಂದ್ರು. \n",
            "ಆದರೆ ಕೊನೆ ಕಿರಿಮಗಳು ಮಾತ್ರ ನಾನ್‌ ಸಾಕಾಕಿಲ್ಲ ಅಂದ್ಲು. ಅಪ್ಪ ನಾವ್‌ ಸಾಕಾಕೆ ಆಗ್ಕದ? \n",
            "ಭಗವಂತ ನಮ್ಮನ್ನೆಲ್ಲ ಸಾಕ್‌ಬೇಕು. ಈ ಮಾತನ್ನೆ ಹೇಳ್ಕೊಂಡು ಬಂದ್ಲು. ಆಗ ಆ\n",
            "--- End of Preview ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8269ac44"
      },
      "source": [
        "**Reasoning**:\n",
        "Load the stop words from the text file, create the output directory, clean the extracted texts by removing stop words, and save the cleaned texts to the specified files.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9ee8731",
        "outputId": "102f1f20-152c-4836-eb9f-795a5eda366f"
      },
      "source": [
        "import os\n",
        "\n",
        "# Load stop words\n",
        "with open('stop-words.txt', 'r', encoding='utf-8') as f:\n",
        "    stop_words = set(f.read().split())\n",
        "\n",
        "# Create output directory\n",
        "output_dir = 'kannada-pre-processed-texts'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "cleaned_files = []\n",
        "\n",
        "# Process each extracted text\n",
        "for filename, text in extracted_texts.items():\n",
        "    # Tokenize (split by whitespace) and filter out stop words\n",
        "    words = text.split()\n",
        "    cleaned_words = [w for w in words if w not in stop_words]\n",
        "    cleaned_text = \" \".join(cleaned_words)\n",
        "\n",
        "    # Determine output filename (change extension to .txt)\n",
        "    # Note: The filename key comes from the previous step, e.g., '1-janapada-kathegalu.pdf'\n",
        "    # We want to save it as '1-janapada-kathegalu.txt'\n",
        "    base_name = os.path.basename(filename)\n",
        "    txt_filename = os.path.splitext(base_name)[0] + \".txt\"\n",
        "    output_path = os.path.join(output_dir, txt_filename)\n",
        "\n",
        "    # Save the cleaned text\n",
        "    with open(output_path, 'w', encoding='utf-8') as f:\n",
        "        f.write(cleaned_text)\n",
        "\n",
        "    cleaned_files.append(output_path)\n",
        "\n",
        "print(\"Extraction and cleaning process completed.\")\n",
        "print(\"Saved files at:\")\n",
        "for path in cleaned_files:\n",
        "    print(path)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extraction and cleaning process completed.\n",
            "Saved files at:\n",
            "kannada-pre-processed-texts/1-janapada-kathegalu.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NHIUv3AJxOVX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}