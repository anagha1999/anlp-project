{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d41f3112",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import pandas as pd\n",
    "MFD2 = 'mfd2.0.dic'\n",
    "nummap = dict()\n",
    "mfd2 = dict()\n",
    "wordmode = True\n",
    "with open(MFD2, 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        ent = line.strip().split()\n",
    "        if line[0] == '%':\n",
    "            wordmode = not wordmode\n",
    "        elif len(ent) > 0:\n",
    "            if wordmode:\n",
    "                #print(ent)\n",
    "                moral = nummap[ent[-1]]\n",
    "                if (moral not in mfd2.keys()):\n",
    "                    mfd2[moral] = []\n",
    "                mfd2[moral].append(''.join([e for e in ent if e not in nummap.keys()]))\n",
    "\n",
    "            # mfd2[]].append(ent[0])\n",
    "            # elif ent[0] in nummap.keys():\n",
    "            #     wordkey = ''.join([e for e in ent if e not in nummap.keys()])\n",
    "            #     mfd2[wordkey] = [nummap[e] for e in ent if e in nummap.keys()]\n",
    "            else:\n",
    "                nummap[ent[0]] = ent[1]\n",
    "\n",
    "# mfd2 = pd.DataFrame.from_dict(mfd2).T\n",
    "# mfd2['foundation'] = mfd2[0]\n",
    "# del mfd2[0]\n",
    "# mfd2 = mfd2.T.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b041b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['care.virtue', 'care.vice', 'fairness.virtue', 'fairness.vice', 'loyalty.virtue', 'loyalty.vice', 'authority.virtue', 'authority.vice', 'sanctity.virtue', 'sanctity.vice'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfd2.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40392e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "foundations = ['care','fairness','loyalty','authority','sanctity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c395b9fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Using cached sentence_transformers-5.1.2-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
      "  Using cached transformers-4.57.1-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting tqdm (from sentence-transformers)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers)\n",
      "  Using cached torch-2.9.0-cp314-cp314-macosx_11_0_arm64.whl.metadata (30 kB)\n",
      "Collecting scikit-learn (from sentence-transformers)\n",
      "  Using cached scikit_learn-1.7.2-cp314-cp314-macosx_12_0_arm64.whl.metadata (11 kB)\n",
      "Collecting scipy (from sentence-transformers)\n",
      "  Using cached scipy-1.16.3-cp314-cp314-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
      "  Downloading huggingface_hub-1.0.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting Pillow (from sentence-transformers)\n",
      "  Using cached pillow-12.0.0-cp314-cp314-macosx_11_0_arm64.whl.metadata (8.8 kB)\n",
      "Collecting typing_extensions>=4.5.0 (from sentence-transformers)\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting filelock (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
      "  Using cached huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.venv/lib/python3.14/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.3.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.14/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (25.0)\n",
      "Collecting pyyaml>=5.1 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached pyyaml-6.0.3-cp314-cp314-macosx_11_0_arm64.whl.metadata (2.4 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading regex-2025.11.3-cp314-cp314-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Collecting requests (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached tokenizers-0.22.1-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached safetensors-0.6.2-cp38-abi3-macosx_11_0_arm64.whl.metadata (4.1 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Using cached fsspec-2025.10.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Using cached hf_xet-1.2.0-cp37-abi3-macosx_11_0_arm64.whl.metadata (4.9 kB)\n",
      "Collecting setuptools (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting sympy>=1.13.3 (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx>=2.5.1 (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch>=1.11.0->sentence-transformers)\n",
      "  Using cached markupsafe-3.0.3-cp314-cp314-macosx_11_0_arm64.whl.metadata (2.7 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached charset_normalizer-3.4.4-cp314-cp314-macosx_10_13_universal2.whl.metadata (37 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached certifi-2025.10.5-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->sentence-transformers)\n",
      "  Using cached joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Using cached sentence_transformers-5.1.2-py3-none-any.whl (488 kB)\n",
      "Using cached transformers-4.57.1-py3-none-any.whl (12.0 MB)\n",
      "Using cached huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "Using cached hf_xet-1.2.0-cp37-abi3-macosx_11_0_arm64.whl (2.7 MB)\n",
      "Using cached tokenizers-0.22.1-cp39-abi3-macosx_11_0_arm64.whl (2.9 MB)\n",
      "Using cached fsspec-2025.10.0-py3-none-any.whl (200 kB)\n",
      "Using cached pyyaml-6.0.3-cp314-cp314-macosx_11_0_arm64.whl (173 kB)\n",
      "Downloading regex-2025.11.3-cp314-cp314-macosx_11_0_arm64.whl (288 kB)\n",
      "Using cached safetensors-0.6.2-cp38-abi3-macosx_11_0_arm64.whl (432 kB)\n",
      "Using cached torch-2.9.0-cp314-cp314-macosx_11_0_arm64.whl (74.4 MB)\n",
      "Using cached networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Using cached filelock-3.20.0-py3-none-any.whl (16 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached markupsafe-3.0.3-cp314-cp314-macosx_11_0_arm64.whl (12 kB)\n",
      "Using cached pillow-12.0.0-cp314-cp314-macosx_11_0_arm64.whl (4.7 MB)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Using cached charset_normalizer-3.4.4-cp314-cp314-macosx_10_13_universal2.whl (207 kB)\n",
      "Using cached idna-3.11-py3-none-any.whl (71 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Using cached certifi-2025.10.5-py3-none-any.whl (163 kB)\n",
      "Using cached scikit_learn-1.7.2-cp314-cp314-macosx_12_0_arm64.whl (8.6 MB)\n",
      "Using cached joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Using cached scipy-1.16.3-cp314-cp314-macosx_14_0_arm64.whl (20.9 MB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Using cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "Installing collected packages: mpmath, urllib3, typing_extensions, tqdm, threadpoolctl, sympy, setuptools, scipy, safetensors, regex, pyyaml, Pillow, networkx, MarkupSafe, joblib, idna, hf-xet, fsspec, filelock, charset_normalizer, certifi, scikit-learn, requests, jinja2, torch, huggingface-hub, tokenizers, transformers, sentence-transformers\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29/29\u001b[0m [sentence-transformers]ence-transformers]\n",
      "\u001b[1A\u001b[2KSuccessfully installed MarkupSafe-3.0.3 Pillow-12.0.0 certifi-2025.10.5 charset_normalizer-3.4.4 filelock-3.20.0 fsspec-2025.10.0 hf-xet-1.2.0 huggingface-hub-0.36.0 idna-3.11 jinja2-3.1.6 joblib-1.5.2 mpmath-1.3.0 networkx-3.5 pyyaml-6.0.3 regex-2025.11.3 requests-2.32.5 safetensors-0.6.2 scikit-learn-1.7.2 scipy-1.16.3 sentence-transformers-5.1.2 setuptools-80.9.0 sympy-1.14.0 threadpoolctl-3.6.0 tokenizers-0.22.1 torch-2.9.0 tqdm-4.67.1 transformers-4.57.1 typing_extensions-4.15.0 urllib3-2.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e6b9805",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anagha/Documents/Fall 2025/anlp-project/.venv/lib/python3.14/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ed9af8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embeddings = {}\n",
    "for foundation, words in mfd2.items():\n",
    "  word_embeddings[foundation] = model.encode(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f86b2972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Master Moral Vectors:\n",
      "care.virtue: [-0.02875727  0.03551083  0.00732217  0.02872039  0.00990646]...\n",
      "care.vice: [-0.01678748  0.05873546  0.0029738   0.04724036  0.00010954]...\n",
      "fairness.virtue: [-0.03395445  0.03819251 -0.01743832 -0.00404897 -0.01426102]...\n",
      "fairness.vice: [-0.0485366   0.03494301 -0.00214647  0.01777522 -0.01023221]...\n",
      "loyalty.virtue: [-0.02538481  0.00370543 -0.02385724  0.01727305 -0.01185597]...\n",
      "loyalty.vice: [-0.04009189  0.01627939 -0.02847462  0.02501947 -0.01733256]...\n",
      "authority.virtue: [-0.02727246  0.03400709 -0.01090748  0.01084201 -0.02491886]...\n",
      "authority.vice: [-0.02178937  0.02740643 -0.01197635  0.01206735 -0.01943187]...\n",
      "sanctity.virtue: [-0.01853777  0.04013454 -0.01779349  0.02171165 -0.02596272]...\n",
      "sanctity.vice: [-0.02264338  0.02221924 -0.00735809  0.01935911 -0.0086274 ]...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "master_moral_vectors = {}\n",
    "for foundation, embeddings in word_embeddings.items():\n",
    "    master_moral_vectors[foundation] = np.mean(embeddings, axis=0)\n",
    "\n",
    "print(\"Master Moral Vectors:\")\n",
    "for foundation, vector in master_moral_vectors.items():\n",
    "    print(f\"{foundation}: {vector[:5]}...\") # Print first 5 elements for brevity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21ce6ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of embeddings: 2114\n",
      "Total number of labels: 2114\n"
     ]
    }
   ],
   "source": [
    "all_embeddings = []\n",
    "embedding_labels = []\n",
    "\n",
    "for foundation, embeddings in word_embeddings.items():\n",
    "    all_embeddings.extend(embeddings)\n",
    "    embedding_labels.extend([f'{foundation} - word'] * len(embeddings))\n",
    "\n",
    "for foundation, vector in master_moral_vectors.items():\n",
    "    all_embeddings.append(vector)\n",
    "    embedding_labels.append(f'{foundation} - master')\n",
    "\n",
    "print(f\"Total number of embeddings: {len(all_embeddings)}\")\n",
    "print(f\"Total number of labels: {len(embedding_labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724ad804",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 2 files: 100%|██████████| 2/2 [02:09<00:00, 64.51s/it] \n",
      "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "def translate_dict_to_kannada(input_dict: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Translates the string values in a dictionary of lists to Kannada.\n",
    "\n",
    "    Args:\n",
    "        input_dict: A dictionary where keys are strings and values are lists of strings.\n",
    "                    Example: {'moral': ['word1', 'word2'], 'moral2': ['word3']}\n",
    "\n",
    "    Returns:\n",
    "        A new dictionary with the same keys but with translated string values.\n",
    "    \"\"\"\n",
    "    # Define the model name and target language\n",
    "    model_name = \"sarvamai/sarvam-translate\"\n",
    "    tgt_lang = \"Kannada\"\n",
    "\n",
    "    # Load the tokenizer and model\n",
    "    # The .to('cuda:0') part moves the model to the GPU for faster inference\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name).to('cuda:0')\n",
    "\n",
    "    translated_dict = {}\n",
    "    # Iterate over each key-value pair in the input dictionary\n",
    "    for key, words in input_dict.items():\n",
    "        translated_words = []\n",
    "        # Iterate over each word in the list\n",
    "        for word in words:\n",
    "            # Create the prompt for the model using a chat template\n",
    "            messages = [\n",
    "                {\"role\": \"system\", \"content\": f\"Translate the text below to {tgt_lang}.\"},\n",
    "                {\"role\": \"user\", \"content\": word}\n",
    "            ]\n",
    "\n",
    "            # Apply the chat template to structure the conversation\n",
    "            text = tokenizer.apply_chat_template(\n",
    "                messages,\n",
    "                tokenize=False,\n",
    "                add_generation_prompt=True\n",
    "            )\n",
    "\n",
    "            # Tokenize the input and move it to the model's device (GPU)\n",
    "            model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "            # Generate the translation\n",
    "            generated_ids = model.generate(\n",
    "                **model_inputs,\n",
    "                max_new_tokens=128,  # Increased token limit for potentially longer words\n",
    "                do_sample=True,\n",
    "                temperature=0.01,\n",
    "                num_return_sequences=1\n",
    "            )\n",
    "\n",
    "            # Decode the generated output to get the translated text\n",
    "            output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist()\n",
    "            output_text = tokenizer.decode(output_ids, skip_special_tokens=True)\n",
    "            translated_words.append(output_text.strip())\n",
    "\n",
    "        # Assign the list of translated words to the corresponding key\n",
    "        translated_dict[key] = translated_words\n",
    "\n",
    "    return translated_dict\n",
    "\n",
    "# --- Example Usage ---\n",
    "\n",
    "\n",
    "# 2. Call the function to get the translated dictionary\n",
    "#    (This requires a machine with a compatible GPU and transformers installed)\n",
    "translated_dictionary = translate_dict_to_kannada(mfd2[\"care.virtue\"])\n",
    "\n",
    "# 3. Print the result\n",
    "print(translated_dictionary)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082eb64a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.14.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
